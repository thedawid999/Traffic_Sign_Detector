# ğŸš¦ Traffic Sign Detector
***
## ğŸ‘¤ Projektinformationen

| **Autor** | thedawid999 |
| :--- | :--- |
| **Studiengang** | Angewandte KÃ¼nstliche Intelligenz |
| **Projekt/Modul** | Computer Vision |

***

## ğŸŒŸ Projektziel

Die Hauptanforderung dieses Projekts ist die Entwicklung und umfassende Evaluation eines **Deep-Learning-basierten Modells** zur **Echtzeit-Verkehrszeichenerkennung**. Das Ziel ist es, eine hohe ZuverlÃ¤ssigkeit und Robustheit unter variablen Bedingungen (Licht, Entfernung) bei gleichzeitiger Erreichung einer niedrigen Latenz (mindestens **30 FPS**) fÃ¼r den Einsatz in Fahrerassistenzsystemen zu gewÃ¤hrleisten.

Um den optimalen Kompromiss zu finden, wurden zwei AnsÃ¤tze verglichen:
1.  **Ansatz A:** YOLO + CNN (Kombinierter Detektions- und Klassifikationsansatz)
2.  **Ansatz B:** YOLO-only (Monolithischer Single-Stage-Detektor)

***

## ğŸ› ï¸ Architektur und Methodik

### Ansatz A: YOLO + CNN (Kombinierte LÃ¶sung)

Dieser zweigleisige Ansatz trennt Lokalisierung und Klassifikation, um die Gesamtleistung zu steigern.

* **1. Detektion (YOLOv11n):** Ein YOLO-Modell ist fÃ¼r die Lokalisierung und das Ausschneiden der Bounding Boxes fÃ¼r die generische Klasse "Verkehrszeichen" verantwortlich.
* **2. Klassifikation (Eigenes CNN):** Ein separates, selbst entwickeltes CNN klassifiziert den ausgeschnittenen Bildausschnitt prÃ¤zise in eine der **43 Verkehrszeichen-Klassen**.

### Ansatz B: YOLO-only (Single-Stage)

Dieser monolithische Detektor fÃ¼hrt Objektdetektion und Klassifizierung in einem einzigen Durchlauf durch.

* **Modell:** Die leistungsstÃ¤rkere **YOLOv11s**-Variante wurde direkt auf den DatensÃ¤tzen fÃ¼r Detektion und Klassifikation trainiert.

***

## ğŸ“š Verwendete Technologien

Das Projekt basiert auf der Programmiersprache **Python** und den folgenden SchlÃ¼sselbibliotheken:

| Technologie | Rolle im Projekt |
| :--- | :--- |
| **Ultralytics** | Training und Evaluation der **YOLO**-Modelle (YOLOv11n/s). |
| **TensorFlow/Keras** | Erstellung und Training des separaten **eigenen CNNs**. |
| **OpenCV** | **Echtzeit-Bild- und Videoanalyse**, Darstellung der Bounding Boxes. |
| **NumPy** | Effiziente Berechnung mit Bilddaten. |

***

## ğŸ’¾ Datengrundlage

FÃ¼r das Training und die Evaluation wurden zwei etablierte deutsche Benchmarks verwendet:

| Datensatz | Fokus | # Klassen | Zweck |
| :--- | :--- | :--- | :--- |
| **GTSDB** | **Lokalisierung** | 1 (VKZ allgemein) | Erkennung der Position von Verkehrszeichen in unzugeschnittenen Bildern (ca. 900 Bilder). |
| **GTSRB** | **Klassifizierung** | 43 | Training der prÃ¤zisen Klassifikation der 43 unterschiedlichen Verkehrszeichen (Ã¼ber 50.000 Bilder). |

***

## ğŸš€ Installation und AusfÃ¼hrung

### 1. AbhÃ¤ngigkeiten installieren

Installieren Sie die notwendigen Bibliotheken in Ihrer Python-Umgebung:

```bash
ultralytics==8.3.203
tensorflow==2.10.0
keras==2.10.0
opencv-python==4.7.0.72
numpy==1.24.2
scikit-learn==1.7.2
matplotlib==3.10.6
```

### 2. AusfÃ¼hren

WÃ¤hlen Sie eine oder mehrere Methoden (`yolo_picutre()`, `yolo_live()`, `picutre()`, `live()`) in der `main.py` und fÃ¼hren Sie diese aus.

## ğŸ¯ Ergebnisse

Die Ergebnisse dieses Projekts sind im **outputs** Ordner zu finden
